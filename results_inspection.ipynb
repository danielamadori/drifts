{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results archive inspection\n",
    "\n",
    "This notebook automatically inspects every `.zip` file stored in the `results` directory.\n",
    "It parses the filename of each archive to extract useful metadata, relies on the included\n",
    "`manifest.json` file to map Redis database dumps to their logical meaning, and previews\n",
    "all extracted files directly below. Large files are truncated to the first bytes so the\n",
    "notebook stays responsive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import zipfile\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "HOST_BASE = 9\n",
    "DB_LABELS = {\n",
    "    0: \"DATA\",\n",
    "    1: \"CAN\",\n",
    "    2: \"R\",\n",
    "    3: \"NR\",\n",
    "    4: \"CAR\",\n",
    "    5: \"AR\",\n",
    "    6: \"GP\",\n",
    "    7: \"BP\",\n",
    "    8: \"PR\",\n",
    "    9: \"AP\",\n",
    "    10: \"LOGS\",\n",
    "}\n",
    "MAX_FULL_BYTES = 200_000\n",
    "MAX_PREVIEW_BYTES = 10_000\n",
    "\n",
    "zip_paths = sorted(RESULTS_DIR.glob(\"*.zip\"))\n",
    "\n",
    "if not zip_paths:\n",
    "    display(Markdown(\"> **No ZIP archives were found in the `results` directory.**\"))\n",
    "else:\n",
    "    display(Markdown(f\"> Found **{len(zip_paths)}** ZIP archives in `{RESULTS_DIR}`.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_bytes(size):\n",
    "    '''Return a human-readable representation of a file size.'''\n",
    "    if size is None:\n",
    "        return \"—\"\n",
    "    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n",
    "    value = float(size)\n",
    "    for unit in units:\n",
    "        if value < 1024 or unit == units[-1]:\n",
    "            if unit == \"B\":\n",
    "                return f\"{int(value)} {unit}\"\n",
    "            return f\"{value:.2f} {unit}\"\n",
    "        value /= 1024\n",
    "    return f\"{value:.2f} B\"\n",
    "\n",
    "\n",
    "def parse_zip_metadata(zip_path):\n",
    "    '''Extract dataset, class, completion flag, and host numbers from the archive name.'''\n",
    "    dataset, class_name, completion_flag, host_fragment = zip_path.stem.rsplit(\"_\", 3)\n",
    "    try:\n",
    "        host_offset = int(host_fragment)\n",
    "        host_id = host_offset + HOST_BASE\n",
    "    except ValueError:\n",
    "        host_offset = None\n",
    "        host_id = None\n",
    "    flag_lower = completion_flag.lower()\n",
    "    if flag_lower in {\"true\", \"false\"}:\n",
    "        is_completed = flag_lower == \"true\"\n",
    "    else:\n",
    "        is_completed = None\n",
    "    return {\n",
    "        \"zip_path\": zip_path,\n",
    "        \"dataset\": dataset,\n",
    "        \"class\": class_name,\n",
    "        \"completion_raw\": completion_flag,\n",
    "        \"is_completed\": is_completed,\n",
    "        \"size_bytes\": zip_path.stat().st_size,\n",
    "        \"host_offset\": host_offset,\n",
    "        \"host_id\": host_id,\n",
    "    }\n",
    "\n",
    "\n",
    "def detect_root_prefix(archive, zip_path):\n",
    "    '''Guess the common directory prefix used inside the archive.'''\n",
    "    stem_prefix = f\"{zip_path.stem}/\"\n",
    "    has_stem = any(\n",
    "        info.filename.startswith(stem_prefix)\n",
    "        for info in archive.infolist()\n",
    "        if not info.is_dir()\n",
    "    )\n",
    "    if has_stem:\n",
    "        return stem_prefix\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def resolve_manifest(archive, zip_path):\n",
    "    '''Return the manifest data together with the prefix used inside the archive.'''\n",
    "    candidates = []\n",
    "    stem_prefix = f\"{zip_path.stem}/\"\n",
    "    candidates.append(stem_prefix)\n",
    "    for info in archive.infolist():\n",
    "        if info.is_dir():\n",
    "            dirname = info.filename\n",
    "            if dirname.startswith(\"__MACOSX/\"):\n",
    "                continue\n",
    "            if not dirname.endswith(\"/\"):\n",
    "                dirname += \"/\"\n",
    "            candidates.append(dirname)\n",
    "    candidates.append(\"\")\n",
    "    seen = set()\n",
    "    for prefix in candidates:\n",
    "        if prefix in seen:\n",
    "            continue\n",
    "        seen.add(prefix)\n",
    "        manifest_path = f\"{prefix}manifest.json\"\n",
    "        try:\n",
    "            with archive.open(manifest_path) as manifest_file:\n",
    "                manifest = json.load(manifest_file)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        else:\n",
    "            return prefix, manifest\n",
    "    raise KeyError(\"manifest.json not found\")\n",
    "\n",
    "\n",
    "def display_db_overview(manifest, archive, prefix):\n",
    "    '''Show a table describing the Redis databases listed in the manifest.'''\n",
    "    header = \"| Label | DB index | JSON file | Size |\\n|-------|----------|-----------|------|\\n\"\n",
    "    rows = []\n",
    "    files_map = manifest.get(\"files\", {})\n",
    "    for db_index in manifest.get(\"databases\", []):\n",
    "        label = DB_LABELS.get(db_index, \"Unknown\")\n",
    "        file_name = files_map.get(str(db_index))\n",
    "        if file_name:\n",
    "            archive_name = f\"{prefix}{file_name}\"\n",
    "            try:\n",
    "                size = archive.getinfo(archive_name).file_size\n",
    "                size_desc = f\"{format_bytes(size)} ({size:,} bytes)\"\n",
    "            except KeyError:\n",
    "                size_desc = \"⚠️ file missing in archive\"\n",
    "        else:\n",
    "            file_name = \"—\"\n",
    "            size_desc = \"⚠️ file not listed\"\n",
    "        rows.append(f\"| {label} | {db_index} | {file_name} | {size_desc} |\")\n",
    "    if rows:\n",
    "        display(Markdown(\"### Redis databases\\n\" + header + \"\\n\".join(rows)))\n",
    "    else:\n",
    "        display(Markdown(\"### Redis databases\\n> Manifest does not describe any Redis database files.\"))\n",
    "\n",
    "\n",
    "def preview_member(archive, info, prefix):\n",
    "    '''Display a preview of a file stored inside the archive.'''\n",
    "    member_name = info.filename\n",
    "    relative_name = member_name[len(prefix):] if prefix and member_name.startswith(prefix) else member_name\n",
    "    size_bytes = info.file_size\n",
    "    size_text = f\"{format_bytes(size_bytes)} ({size_bytes:,} bytes)\"\n",
    "    heading_lines = [f\"### {relative_name}\", f\"* Size: {size_text}\"]\n",
    "    with archive.open(member_name) as handle:\n",
    "        if size_bytes <= MAX_FULL_BYTES:\n",
    "            payload = handle.read()\n",
    "            text = payload.decode(\"utf-8\", errors=\"replace\")\n",
    "            body_lines = heading_lines + [\"\", \"````text\", text, \"````\"]\n",
    "        else:\n",
    "            payload = handle.read(MAX_PREVIEW_BYTES)\n",
    "            text = payload.decode(\"utf-8\", errors=\"replace\")\n",
    "            remaining = max(size_bytes - MAX_PREVIEW_BYTES, 0)\n",
    "            body_lines = (\n",
    "                heading_lines\n",
    "                + [f\"* Previewed: first {MAX_PREVIEW_BYTES:,} bytes\", \"\", \"````text\", text, \"````\", \"\"]\n",
    "                + [\n",
    "                    f\"> ⚠️ Preview truncated. {remaining:,} additional bytes are not shown.\",\n",
    "                    \"> Extract the file from the archive to inspect it entirely.\",\n",
    "                ]\n",
    "            )\n",
    "    display(Markdown(\"\\n\".join(body_lines)))\n",
    "\n",
    "\n",
    "def display_zip_contents(zip_path):\n",
    "    '''Render metadata, manifest information, and file previews for a single archive.'''\n",
    "    meta = parse_zip_metadata(zip_path)\n",
    "    size_text = f\"{format_bytes(meta['size_bytes'])} ({meta['size_bytes']:,} bytes)\"\n",
    "    completion = (\n",
    "        \"True\" if meta[\"is_completed\"] is True else \"False\" if meta[\"is_completed\"] is False else meta[\"completion_raw\"]\n",
    "    )\n",
    "    host_offset = meta[\"host_offset\"] if meta[\"host_offset\"] is not None else \"—\"\n",
    "    host_id = meta[\"host_id\"] if meta[\"host_id\"] is not None else \"—\"\n",
    "    lines = [\n",
    "        f\"## Archive: `{zip_path.name}`\",\n",
    "        f\"* Dataset: **{meta['dataset']}**\",\n",
    "        f\"* Class: **{meta['class']}**\",\n",
    "        f\"* Completed flag: **{completion}**\",\n",
    "        f\"* Host offset: **{host_offset}** (host id starting from 9: **{host_id}**)\",\n",
    "        f\"* Archive size: **{size_text}**\",\n",
    "    ]\n",
    "    display(Markdown(\"\\n\".join(lines)))\n",
    "\n",
    "    with zipfile.ZipFile(zip_path) as archive:\n",
    "        try:\n",
    "            prefix, manifest = resolve_manifest(archive, zip_path)\n",
    "            manifest_error = None\n",
    "        except KeyError as exc:\n",
    "            manifest = None\n",
    "            manifest_error = str(exc)\n",
    "            prefix = detect_root_prefix(archive, zip_path)\n",
    "        except json.JSONDecodeError as exc:\n",
    "            manifest = None\n",
    "            manifest_error = f\"Could not parse manifest.json: {exc}\"\n",
    "            prefix = detect_root_prefix(archive, zip_path)\n",
    "\n",
    "        if manifest:\n",
    "            display(Markdown(\"### Manifest summary\"))\n",
    "            display(Markdown(f\"* File prefix: `{manifest.get('file_prefix', '—')}`\"))\n",
    "            display_db_overview(manifest, archive, prefix)\n",
    "        else:\n",
    "            display(Markdown(f\"> ⚠️ {manifest_error}\"))\n",
    "\n",
    "        members = sorted(\n",
    "            (info for info in archive.infolist() if not info.is_dir()),\n",
    "            key=lambda info: info.filename,\n",
    "        )\n",
    "        for info in members:\n",
    "            preview_member(archive, info, prefix)\n",
    "\n",
    "\n",
    "metadata = [parse_zip_metadata(path) for path in zip_paths]\n",
    "if metadata:\n",
    "    header = (\n",
    "        \"| Dataset | Class | Completed flag | Host offset | Host id | Archive size | Archive file |\\n\"\n",
    "        \"|---------|-------|----------------|-------------|---------|--------------|--------------|\\n\"\n",
    "    )\n",
    "    rows = []\n",
    "    for item in metadata:\n",
    "        completion = (\n",
    "            \"True\" if item[\"is_completed\"] is True else \"False\" if item[\"is_completed\"] is False else item[\"completion_raw\"]\n",
    "        )\n",
    "        host_offset = item[\"host_offset\"] if item[\"host_offset\"] is not None else \"—\"\n",
    "        host_id = item[\"host_id\"] if item[\"host_id\"] is not None else \"—\"\n",
    "        size_text = f\"{format_bytes(item['size_bytes'])} ({item['size_bytes']:,} bytes)\"\n",
    "        rows.append(\n",
    "            f\"| {item['dataset']} | {item['class']} | {completion} | {host_offset} | {host_id} | {size_text} | {item['zip_path'].name} |\"\n",
    "        )\n",
    "    display(Markdown(\"### Archive overview\\n\" + header + \"\\n\".join(rows)))\n",
    "else:\n",
    "    display(Markdown(\"> **No archives to summarise.**\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if zip_paths:\n",
    "    for path in zip_paths:\n",
    "        display_zip_contents(path)\n",
    "else:\n",
    "    display(Markdown(\"> No archives to inspect.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}