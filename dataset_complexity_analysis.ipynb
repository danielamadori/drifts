{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Complexity Analysis\n",
        "\n",
        "This notebook explores the Random Forest complexity metrics contained in ``forest_report.json``. It replicates the logic used by ``sort_datasets_by_complexity.py`` and enriches it with tabular views and visualisations to better understand how each dataset compares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the dataset report\n",
        "\n",
        "The JSON report is generated by ``dataset_forest_report.py``. Each entry contains metadata about the dataset alongside summary statistics for the optimised Random Forest model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Any, Mapping\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "REPORT_PATH = Path('forest_report.json')\n",
        "REPORT_PATH.resolve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with REPORT_PATH.open('r', encoding='utf-8') as handle:\n",
        "    report_data: list[dict[str, Any]] = json.load(handle)\n",
        "\n",
        "len(report_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a summary table\n",
        "\n",
        "We derive a single ``forest_dimension`` metric by multiplying the number of estimators by the average number of nodes per tree. This is the same approximation used by the CLI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_forest_dimension(statistics: Mapping[str, Any] | None) -> float:\n",
        "    if not isinstance(statistics, Mapping):\n",
        "        return 0.0\n",
        "    n_estimators = statistics.get('n_estimators')\n",
        "    avg_nodes = statistics.get('avg_nodes')\n",
        "    try:\n",
        "        return float(n_estimators) * float(avg_nodes)\n",
        "    except (TypeError, ValueError):\n",
        "        return 0.0\n",
        "\n",
        "def extract_metadata(entry: Mapping[str, Any]) -> dict[str, Any]:\n",
        "    metadata = entry.get('metadata')\n",
        "    statistics = entry.get('forest_statistics')\n",
        "\n",
        "    dataset = str(entry.get('dataset', '')) or '<unknown>'\n",
        "    series_length = metadata.get('series_length') if isinstance(metadata, Mapping) else None\n",
        "    train_size = metadata.get('train_size') if isinstance(metadata, Mapping) else None\n",
        "    test_size = metadata.get('test_size') if isinstance(metadata, Mapping) else None\n",
        "\n",
        "    return {\n",
        "        'dataset': dataset,\n",
        "        'forest_dimension': compute_forest_dimension(statistics if isinstance(statistics, Mapping) else None),\n",
        "        'series_length': int(series_length) if series_length is not None else None,\n",
        "        'train_size': int(train_size) if train_size is not None else None,\n",
        "        'test_size': int(test_size) if test_size is not None else None,\n",
        "        'avg_depth': float(statistics.get('avg_depth')) if isinstance(statistics, Mapping) and statistics.get('avg_depth') is not None else None,\n",
        "        'avg_leaves': float(statistics.get('avg_leaves')) if isinstance(statistics, Mapping) and statistics.get('avg_leaves') is not None else None,\n",
        "        'avg_nodes': float(statistics.get('avg_nodes')) if isinstance(statistics, Mapping) and statistics.get('avg_nodes') is not None else None,\n",
        "        'n_estimators': int(statistics.get('n_estimators')) if isinstance(statistics, Mapping) and statistics.get('n_estimators') is not None else None,\n",
        "    }\n",
        "\n",
        "summary_rows = [extract_metadata(entry) for entry in report_data]\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df = summary_df.sort_values(['forest_dimension', 'series_length', 'dataset'], ascending=[False, False, True]).reset_index(drop=True)\n",
        "summary_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full dataset ranking\n",
        "\n",
        "The full table mirrors the CLI output but includes additional metadata for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "styled_summary = summary_df.style.format({\n",
        "    'forest_dimension': '{:,.2f}'.format,\n",
        "    'avg_depth': '{:.2f}'.format,\n",
        "    'avg_leaves': '{:,.2f}'.format,\n",
        "    'avg_nodes': '{:,.2f}'.format,\n",
        "})\n",
        "styled_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Top datasets by forest complexity\n",
        "\n",
        "A horizontal bar chart provides a compact overview of the datasets with the largest forests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_n = 20\n",
        "top_complex = summary_df.head(top_n)\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.barh(top_complex['dataset'], top_complex['forest_dimension'], color='#1f77b4')\n",
        "ax.set_xlabel('Forest dimension (n_estimators \u00d7 avg_nodes)')\n",
        "ax.set_ylabel('Dataset')\n",
        "ax.set_title(f'Top {top_n} datasets by forest complexity')\n",
        "ax.invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complexity vs. series length\n",
        "\n",
        "The scatter plot below highlights whether longer time series also require larger forests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.scatter(summary_df['series_length'], summary_df['forest_dimension'], s=60, alpha=0.7)\n",
        "ax.set_xlabel('Series length')\n",
        "ax.set_ylabel('Forest dimension')\n",
        "ax.set_title('Forest complexity vs. series length')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribution of forest complexity\n",
        "\n",
        "Finally, a histogram shows the spread of the forest dimension metric across all datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.hist(summary_df['forest_dimension'], bins=20, color='#ff7f0e', edgecolor='black', alpha=0.8)\n",
        "ax.set_xlabel('Forest dimension')\n",
        "ax.set_ylabel('Number of datasets')\n",
        "ax.set_title('Distribution of forest complexity')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}