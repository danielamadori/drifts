{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae0ee7b",
   "metadata": {},
   "source": [
    "\n",
    "# models_analysis_enriched â€” Portable Version\n",
    "\n",
    "Questo notebook calcola e unisce i conteggi di **Reason categories** (CAN, R, NR, CAR, AR, GP, BP, PR, AP)\n",
    "dai file `redis_backup_db*.json` trovati nella sottocartella `results/`, con eventuale merge con `forest_report.csv`.\n",
    "\n",
    "âš™ï¸ Funziona in **qualsiasi percorso**: basta che nella stessa directory ci sia la cartella `results/`\n",
    "e (facoltativamente) il file `forest_report.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:35:13.905664Z",
     "start_time": "2025-10-26T21:35:13.863134Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "from drifts_results import compute_counts_from_results, load_analyzed_df, cast_dataset_str, CAT_LIST, DB_TO_CAT\n",
    "# Detect notebook base directory as robustly as possible\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "    BASE_DIR = Path(ip.run_line_magic('pwd', '')).resolve()\n",
    "except Exception:\n",
    "    BASE_DIR = Path.cwd().resolve()\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "FR_CSV = BASE_DIR / 'forest_report.csv'\n"
   ],
   "id": "c96540fc07174bda",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (drifts_results.py, line 36)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001B[36m(most recent call last)\u001B[39m:\n",
      "  File \u001B[92m~/Projects/drifts/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3699\u001B[39m in \u001B[95mrun_code\u001B[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001B[36m  \u001B[39m\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[33]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mfrom drifts_results import compute_counts_from_results, load_analyzed_df, cast_dataset_str, CAT_LIST, DB_TO_CAT\u001B[39m\n",
      "  \u001B[36mFile \u001B[39m\u001B[32m~/Projects/drifts/drifts_results.py:36\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31m)\u001B[39m\n    ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m unmatched ')'\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json, re, pandas as pd\n",
    "from drifts_results import compute_counts_from_results, load_analyzed_df, cast_dataset_str, CAT_LIST, DB_TO_CAT\n",
    "\n",
    "# === Rilevamento automatico dei percorsi (robusto per notebook) ===\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()\n",
    "    BASE_DIR = Path(ip.run_line_magic('pwd', '')).resolve()\n",
    "except Exception:\n",
    "    BASE_DIR = Path.cwd().resolve()\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "FR_CSV = BASE_DIR / \"forest_report.csv\"\n",
    "\n",
    "print(\"ðŸ“ BASE_DIR     :\", BASE_DIR)\n",
    "print(\"ðŸ“ RESULTS_DIR  :\", RESULTS_DIR)\n",
    "print(\"ðŸ“„ FOREST_REPORT:\", FR_CSV.exists())\n"
   ],
   "id": "f776ecdc211db8ff"
  },
  {
   "cell_type": "code",
   "id": "5f92b11f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:35:13.909723Z",
     "start_time": "2025-10-26T19:38:29.200592Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# === Calcolo e merge ===\n",
    "\n",
    "\n",
    "\n",
    "counts_df = compute_counts_from_results(RESULTS_DIR, verbose=True)\n",
    "\n",
    "analyzed_df = load_analyzed_df(FR_CSV)\n",
    "\n",
    "counts_df   = cast_dataset_str(counts_df)\n",
    "\n",
    "analyzed_df = cast_dataset_str(analyzed_df)\n",
    "\n",
    "\n",
    "\n",
    "# Diagnostic: inspect zip archives for redis manifests\n",
    "import zipfile\n",
    "missing = []\n",
    "for z in sorted(RESULTS_DIR.glob('*.zip')):\n",
    "    try:\n",
    "        with zipfile.ZipFile(z, 'r') as zz:\n",
    "            names = zz.namelist()\n",
    "            has = any('redis_backup_db' in n for n in names)\n",
    "            if not has:\n",
    "                missing.append((z.name, names[:10]))\n",
    "    except Exception as e:\n",
    "        missing.append((z.name, f'error: {e}'))\n",
    "\n",
    "if missing:\n",
    "    print('ZIP senza redis manifest (primi entry mostrati):')\n",
    "    for name, sample in missing:\n",
    "        print('-', name, '->', sample)\n",
    "else:\n",
    "    print('Tutti gli zip contengono redis_backup_db*.json (o non ci sono zip).')\n",
    "\n",
    "# Restringi ai dataset presenti in results/\n",
    "\n",
    "results_datasets = sorted(set([p.name.split(\"_\")[0] if \"_\" in p.name else p.name\n",
    "\n",
    "                               for p in RESULTS_DIR.glob(\"*\") if p.is_dir() and any(p.rglob(\"redis_backup_db*.json\"))]))\n",
    "\n",
    "analyzed_df_res = analyzed_df[analyzed_df[\"dataset\"].isin(results_datasets)].copy()\n",
    "\n",
    "\n",
    "\n",
    "# Inner join\n",
    "\n",
    "merged_results_only = analyzed_df_res.merge(counts_df, on=\"dataset\", how=\"inner\")\n",
    "\n",
    "\n",
    "\n",
    "# Fill e cast\n",
    "\n",
    "for c in DB_TO_CAT.values():\n",
    "\n",
    "    if c not in merged_results_only.columns:\n",
    "\n",
    "        merged_results_only[c] = 0\n",
    "\n",
    "merged_results_only[list(DB_TO_CAT.values())] = merged_results_only[list(DB_TO_CAT.values())].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Aggiungi colonne derivate\n",
    "\n",
    "merged_results_only[\"TOT\"] = merged_results_only[list(DB_TO_CAT.values())].sum(axis=1)\n",
    "\n",
    "merged_results_only[\"%R\"]  = (100*merged_results_only[\"R\"]/merged_results_only[\"TOT\"]).round(2).replace([float(\"inf\"),float(\"nan\")],0)\n",
    "\n",
    "merged_results_only[\"%NR\"] = (100*merged_results_only[\"NR\"]/merged_results_only[\"TOT\"]).round(2).replace([float(\"inf\"),float(\"nan\")],0)\n",
    "\n",
    "\n",
    "\n",
    "merged_results_only = merged_results_only.sort_values(\"R\", ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# Visualizza tabella\n",
    "\n",
    "try:\n",
    "\n",
    "    _ = style_summary_table\n",
    "\n",
    "except NameError:\n",
    "\n",
    "    def style_summary_table(df: pd.DataFrame):\n",
    "\n",
    "        return (df.style.set_properties(**{\"text-align\":\"left\"})\n",
    "\n",
    "                    .set_table_styles([{\"selector\":\"th\",\"props\":[(\"text-align\",\"left\")]}]))\n",
    "\n",
    "style_summary_table(merged_results_only)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10d474e90>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5df0a th {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5df0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5df0a_level0_col0\" class=\"col_heading level0 col0\" >dataset</th>\n",
       "      <th id=\"T_5df0a_level0_col1\" class=\"col_heading level0 col1\" >status</th>\n",
       "      <th id=\"T_5df0a_level0_col2\" class=\"col_heading level0 col2\" >endpoints_universe</th>\n",
       "      <th id=\"T_5df0a_level0_col3\" class=\"col_heading level0 col3\" >error</th>\n",
       "      <th id=\"T_5df0a_level0_col4\" class=\"col_heading level0 col4\" >eu_complexity</th>\n",
       "      <th id=\"T_5df0a_level0_col5\" class=\"col_heading level0 col5\" >mean_eu</th>\n",
       "      <th id=\"T_5df0a_level0_col6\" class=\"col_heading level0 col6\" >n_features</th>\n",
       "      <th id=\"T_5df0a_level0_col7\" class=\"col_heading level0 col7\" >test_score</th>\n",
       "      <th id=\"T_5df0a_level0_col8\" class=\"col_heading level0 col8\" >validation_score</th>\n",
       "      <th id=\"T_5df0a_level0_col9\" class=\"col_heading level0 col9\" >metadata_classes</th>\n",
       "      <th id=\"T_5df0a_level0_col10\" class=\"col_heading level0 col10\" >metadata_dataset</th>\n",
       "      <th id=\"T_5df0a_level0_col11\" class=\"col_heading level0 col11\" >metadata_first_class</th>\n",
       "      <th id=\"T_5df0a_level0_col12\" class=\"col_heading level0 col12\" >metadata_length_consistent</th>\n",
       "      <th id=\"T_5df0a_level0_col13\" class=\"col_heading level0 col13\" >metadata_n_channels</th>\n",
       "      <th id=\"T_5df0a_level0_col14\" class=\"col_heading level0 col14\" >metadata_n_classes</th>\n",
       "      <th id=\"T_5df0a_level0_col15\" class=\"col_heading level0 col15\" >metadata_series_length</th>\n",
       "      <th id=\"T_5df0a_level0_col16\" class=\"col_heading level0 col16\" >metadata_test_size</th>\n",
       "      <th id=\"T_5df0a_level0_col17\" class=\"col_heading level0 col17\" >metadata_train_size</th>\n",
       "      <th id=\"T_5df0a_level0_col18\" class=\"col_heading level0 col18\" >best_params_bootstrap</th>\n",
       "      <th id=\"T_5df0a_level0_col19\" class=\"col_heading level0 col19\" >best_params_ccp_alpha</th>\n",
       "      <th id=\"T_5df0a_level0_col20\" class=\"col_heading level0 col20\" >best_params_criterion</th>\n",
       "      <th id=\"T_5df0a_level0_col21\" class=\"col_heading level0 col21\" >best_params_max_depth</th>\n",
       "      <th id=\"T_5df0a_level0_col22\" class=\"col_heading level0 col22\" >best_params_max_features</th>\n",
       "      <th id=\"T_5df0a_level0_col23\" class=\"col_heading level0 col23\" >best_params_max_leaf_nodes</th>\n",
       "      <th id=\"T_5df0a_level0_col24\" class=\"col_heading level0 col24\" >best_params_max_samples</th>\n",
       "      <th id=\"T_5df0a_level0_col25\" class=\"col_heading level0 col25\" >best_params_min_impurity_decrease</th>\n",
       "      <th id=\"T_5df0a_level0_col26\" class=\"col_heading level0 col26\" >best_params_min_samples_leaf</th>\n",
       "      <th id=\"T_5df0a_level0_col27\" class=\"col_heading level0 col27\" >best_params_min_samples_split</th>\n",
       "      <th id=\"T_5df0a_level0_col28\" class=\"col_heading level0 col28\" >best_params_n_estimators</th>\n",
       "      <th id=\"T_5df0a_level0_col29\" class=\"col_heading level0 col29\" >best_params_random_state</th>\n",
       "      <th id=\"T_5df0a_level0_col30\" class=\"col_heading level0 col30\" >forest_statistics_avg_depth</th>\n",
       "      <th id=\"T_5df0a_level0_col31\" class=\"col_heading level0 col31\" >forest_statistics_avg_leaves</th>\n",
       "      <th id=\"T_5df0a_level0_col32\" class=\"col_heading level0 col32\" >forest_statistics_avg_nodes</th>\n",
       "      <th id=\"T_5df0a_level0_col33\" class=\"col_heading level0 col33\" >forest_statistics_max_depth</th>\n",
       "      <th id=\"T_5df0a_level0_col34\" class=\"col_heading level0 col34\" >forest_statistics_min_depth</th>\n",
       "      <th id=\"T_5df0a_level0_col35\" class=\"col_heading level0 col35\" >forest_statistics_n_estimators</th>\n",
       "      <th id=\"T_5df0a_level0_col36\" class=\"col_heading level0 col36\" >analyzed</th>\n",
       "      <th id=\"T_5df0a_level0_col37\" class=\"col_heading level0 col37\" >CAN</th>\n",
       "      <th id=\"T_5df0a_level0_col38\" class=\"col_heading level0 col38\" >R</th>\n",
       "      <th id=\"T_5df0a_level0_col39\" class=\"col_heading level0 col39\" >NR</th>\n",
       "      <th id=\"T_5df0a_level0_col40\" class=\"col_heading level0 col40\" >CAR</th>\n",
       "      <th id=\"T_5df0a_level0_col41\" class=\"col_heading level0 col41\" >AR</th>\n",
       "      <th id=\"T_5df0a_level0_col42\" class=\"col_heading level0 col42\" >GP</th>\n",
       "      <th id=\"T_5df0a_level0_col43\" class=\"col_heading level0 col43\" >BP</th>\n",
       "      <th id=\"T_5df0a_level0_col44\" class=\"col_heading level0 col44\" >PR</th>\n",
       "      <th id=\"T_5df0a_level0_col45\" class=\"col_heading level0 col45\" >AP</th>\n",
       "      <th id=\"T_5df0a_level0_col46\" class=\"col_heading level0 col46\" >TOT</th>\n",
       "      <th id=\"T_5df0a_level0_col47\" class=\"col_heading level0 col47\" >%R</th>\n",
       "      <th id=\"T_5df0a_level0_col48\" class=\"col_heading level0 col48\" >%NR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "f68edbb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:35:13.914335Z",
     "start_time": "2025-10-26T19:38:29.248281Z"
    }
   },
   "source": [
    "\n",
    "# === Esporta CSV ===\n",
    "OUT = BASE_DIR / \"analyzed_counts_results_only.csv\"\n",
    "merged_results_only.to_csv(OUT, index=False)\n",
    "print(\"âœ… Esportato:\", OUT)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Esportato: /Users/danielamadori/Projects/drifts/analyzed_counts_results_only.csv\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
